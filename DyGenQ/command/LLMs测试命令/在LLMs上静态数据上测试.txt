------在LLMs上静态数据上测试------------
python 05CQ_Test_Eval.py \
    --prompt ./promptEn/CQTest.txt \
    --dataset ./dataset/formatDataset/mmlu/mmlu_sample_300.json \
    --model gpt3 \
    --output ./output/CQ_gpt3_Answer.json
    
python 08countScoreCQ.py \
    --json ./output/CQ_gpt3_Answer.json

177/300=0.590

python 05CQ_Test_Eval.py \
    --prompt ./promptEn/CQTest.txt \
    --dataset ./dataset/formatDataset/mmlu/mmlu_sample_300.json \
    --model gpt4 \
    --output ./output/CQ_gpt4_Answer.json
    
python 08countScoreCQ.py \
    --json ./output/CQ_gpt4_Answer.json
179/300=0.597

python 05CQ_Test_Eval.py \
    --prompt ./promptEn/CQTest.txt \
    --dataset ./dataset/formatDataset/mmlu/mmlu_sample_300.json \
    --model doub \
    --output ./output/CQ_doub_Answer.json
    
python 08countScoreCQ.py \
    --json ./output/CQ_doub_Answer.json
237/300=0.790

python 05CQ_Test_Eval.py \
    --prompt ./promptEn/CQTest.txt \
    --dataset ./dataset/formatDataset/mmlu/mmlu_sample_300.json \
    --model qwen \
    --output ./output/CQ_qwen_Answer.json
    
python 08countScoreCQ.py \
    --json ./output/CQ_qwen_Answer.json
234/300=0.780


python 05CQ_Test_Eval.py \
    --prompt ./promptEn/CQTest.txt \
    --dataset ./dataset/formatDataset/mmlu/mmlu_sample_300.json \
    --model claude3 \
    --output ./output/CQ_claude3_Answer.json
    
python 08countScoreCQ.py \
    --json ./output/CQ_claude3_Answer.json
196/300=0.653